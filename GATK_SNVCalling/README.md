# Caveat

  This README is a lite version. If you want to see more details on each command line, please go to Doc folder
  Please also read carefully for the GATK best practices mannual.

# Introduction
- All data were aligned to reference genome GRCh37 (hg19) with bwa 0.7.17 mem. <br>
- We followed the GATK (4.0.5.1) SNV calling best practices (https://gatk.broadinstitute.org/hc/en-us/articles/360035535932-Germline-short-variant-discovery-SNPs-Indels-) and only two parameters were changed to accommodate computational resources (--max_records_in_ram and --max-reads-per-alignment-start). <br>
- The major procedures include 1) remove duplication with Picard, 2) Recalibrate Base Quality; 3) Combine all samples together and run HaplotypeCaller and generate GVCF; 4) Consolidate GVCF and Joint call all variants with CombineGVCF and GenotypeGVCF; <br>
- Finally, all high-quality variants were preserved if 1) the quality score is high (QD>=5,QUAL>=50, FS<=60, MQ>=40, MQRankSum>=-12.5, ReadPosRankSum=>-8, SOR<=3),  and 2) there are no SNV clusters within 10 bp (--cluster-size 3, --cluster-window-size 10). 

# Pipeline
### Layout of your folder:
- Pipeline: for all your pipeline
- FASTQ: for all you raw FASTQ files and all following BAM files;
- CombineGVCF: temporay folder for CombineGVCF 
- GenotypeGVCF: temporay folder for GenotypeGVCF
- Final_VCF:  Final_VCF folder

### Prepare

Create new folder that are going to use. 

All useful scripts are located in src folder. Please include the full path src first OR export $PATH=$PATH:./src

### Step 1, Mapping with BWA, S1.bwa.sh
Assume you have downloaded the reference and created the index file. If not, use bwa index YOUR_REFERENCE_FASTA_FILE and find more details here: http://bio-bwa.sourceforge.net/bwa.shtml

Input for mapping here is FASTQ. If your input is BAM file, please go to https://github.com/CancerGenome/Bioinformatics_Pipeline/tree/master/VarScan_SomaticSNVCalling Step One.

- One Step to generate the BWA running shell.

> S1.bwa.pl BAM_LIST > S1.bwa.sh

> sh S1.bwa.sh 

Where BAM_LIST format is: FULL PATH BAM, one line each. 
Please replace /home/yulywang/db/human/hs37d5 and /home/yulywang/db/human/hs37d5.fai with your own reference index and index fai.

### Step 2, Mark Duplicaton with Picard, S2.picard.sh

Run picard to label duplication.

> picard.sh TEST.sort.bam TEST

where TEST.sort.bam is sorted bam file generated by BWA, TEST is the prefix for all OUTPUT

### Step 3, Base Quality Recalibration and GVCF Infer, S3.BQSR_GVCF.sh

Run Base Quality Recalibartion and Call GVCF 

> GATK_BQSR_GVCF.sh TEST.rmdup.bam TEST

where TEST.rmdup.bam is duplication-labelled bam file generated by Picard, TEST is the prefix for all OUTPUT

### Caveat: Samples are not dependent for analysis above. For analysis below, you need to wait for all samples finished.

### Step 4 - 8 Combine GVCF, Merge Genotype, Hard Filtering and Annotation, S5_8_CombineGVCF_Merge_GenotypeGVCF_HardFilter_Annovar.sh

After all samples have their own GVCF files, combine GVCF for each 30M, concat together, hard filtering for variants, and annotation. One command to run Step 4-8:

> ls *.g.vcf.gz > GVCF.list

> GATK_CombineGVCF_Merge_GenotypeGVCF_HardFilter_Annovar.pl -l GVCF.list > S5_8_CombineGVCF_Merge_GenotypeGVCF_HardFilter_Annovar.sh

> sh GATK_CombineGVCF_Merge_GenotypeGVCF_HardFilter_Annovar.sh

### Step 9 Concat all together.

Concat all together: 
> sh S9.Concat_after_Annovar.sh
